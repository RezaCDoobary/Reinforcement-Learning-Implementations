{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import environments\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from replaybuffer import *\n",
    "\n",
    "from library import *\n",
    " \n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n/Users/rezacolindoobary/opt/anaconda3/envs/ml_env/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n  result = entry_point.load(False)\n"
    }
   ],
   "source": [
    "env1 = environments.environment_gym('Acrobot-v1')\n",
    "env = environments.env_wrapper(env1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_action = env.action_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the replay buffer storing facility\n",
    "def store(env, n_episodes, replaybuffer, window = 100):\n",
    "    scores = []\n",
    "    moving_scores = deque(maxlen = window)\n",
    "    moving_average_scores = []\n",
    "    for i_epsiodes in range(0,n_episodes):\n",
    "        print('\\r','Episode [{}/{}]'.format(i_epsiodes, n_episodes),end='')\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        while not done:\n",
    "            next_action = env.env.action_space_sample()\n",
    "            next_state, reward, done, _ = env.step(next_action)\n",
    "            score+=reward\n",
    "            replaybuffer.add(state,next_action, reward, next_state, done)\n",
    "            state = next_state\n",
    "        scores.append(score)\n",
    "        moving_scores.append(score)\n",
    "        moving_average_scores.append(np.mean(moving_scores))\n",
    "    return np.mean(scores), scores, moving_average_scores, replaybuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": " Episode [9/10]"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb = ReplayBuffer(action_size = n_action,buffer_size = 100,batch_size = 10,seed = 12345)\n",
    "_ = store(env, 10, rb, window=100)\n",
    "\n",
    "_ = rb.sample()\n",
    "len(_[0]) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": " Episode [14/15]max -500.0\n"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 383.667187 248.518125\" width=\"383.667187pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 383.667187 248.518125 \nL 383.667187 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 41.667188 224.64 \nL 376.467188 224.64 \nL 376.467188 7.2 \nL 41.667188 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m2cdd17d8ab\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.885369\" xlink:href=\"#m2cdd17d8ab\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(53.704119 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"124.521733\" xlink:href=\"#m2cdd17d8ab\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(121.340483 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"192.158097\" xlink:href=\"#m2cdd17d8ab\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(188.976847 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"259.79446\" xlink:href=\"#m2cdd17d8ab\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(256.61321 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"327.430824\" xlink:href=\"#m2cdd17d8ab\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(324.249574 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m38f92d082e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"41.667188\" xlink:href=\"#m38f92d082e\" y=\"194.989091\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- −520 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 198.78831)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"41.667188\" xlink:href=\"#m38f92d082e\" y=\"155.454545\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- −510 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(7.2 159.253764)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"41.667188\" xlink:href=\"#m38f92d082e\" y=\"115.92\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- −500 -->\n      <g transform=\"translate(7.2 119.719219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"41.667188\" xlink:href=\"#m38f92d082e\" y=\"76.385455\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- −490 -->\n      <defs>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n      </defs>\n      <g transform=\"translate(7.2 80.184673)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"41.667188\" xlink:href=\"#m38f92d082e\" y=\"36.850909\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −480 -->\n      <g transform=\"translate(7.2 40.650128)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"211.035156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path clip-path=\"url(#p6f6402ff6f)\" d=\"M 56.885369 115.92 \nL 90.703551 115.92 \nL 124.521733 115.92 \nL 158.339915 115.92 \nL 192.158097 115.92 \nL 225.976278 115.92 \nL 259.79446 115.92 \nL 293.612642 115.92 \nL 327.430824 115.92 \nL 361.249006 115.92 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 41.667188 224.64 \nL 41.667188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 376.467188 224.64 \nL 376.467188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 41.667188 224.64 \nL 376.467188 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 41.667188 7.2 \nL 376.467188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p6f6402ff6f\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"41.667188\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#random policy\n",
    "#policy = lib.random()\n",
    "#Q = defaultdict(lambda: np.zeros(n_actions))\n",
    "mean_scores, score, moving_window, rb = store(env, 15,rb)\n",
    "moving_window = moving_window[5:]\n",
    "print('max',max(moving_window))\n",
    "plt.plot(moving_window)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(state_size, action_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\nEpisode 1\tAverage Score: -500.00[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n2\n1\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n1\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n1\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n1\n[0]\n0\n1\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n1\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n1\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\nEpisode 2\tAverage Score: -500.00[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n2\n1\n1\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n1\n[0]\n0\n[0]\n0\n1\n[0]\n0\n[0]\n0\n2\n2\n2\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n1\n1\n1\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n2\n2\n2\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n2\n2\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n2\n2\n1\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n1\n[0]\n0\n1\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n1\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n1\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n1\n1\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n1\n[0]\n0\n1\n[0]\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n1\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n1\n[0]\n0\n[0]\n0\n0\n2\n2\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n1\n[0]\n0\n[0]\n0\n[0]\n0\n0\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n1\n1\n1\n1\n[0]\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n0\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n1\n1\n1\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n2\n[0]\n0\n2\n1\n1\n[0]\n0\n[0]\n0\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n1\n[0]\n0\n[0]\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n1\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n1\n1\n[0]\n0\n1\n[0]\n0\n[0]\n0\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n1\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n1\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n2\n1\n[0]\n0\n1\n1\n1\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n1\n[0]\n0\n1\n[0]\n0\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n2\n[0]\n0\n2\n2\n2\n[0]\n0\n1\n[0]\n0\n0\n0\n[0]\n0\n2\n[0]\n0\n[0]\n0\n[0]\n0\n2\n2\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\n[0]\n0\nEpisode 3\tAverage Score: -500.00[0]\n0\n2\n[0]\n0\n[0]\n0\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4918445ae179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn_config_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolved_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_at_goal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-4918445ae179>\u001b[0m in \u001b[0;36mdqn\u001b[0;34m(env, agent, policy, n_episodes, max_t, stop_at_goal, goal)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4918445ae179>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Seagate/RL/RLImplementation/Reinforcement-Learning-Implementations/replaybuffer.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_state\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml_env/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;31m# raise warning if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml_env/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class config:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__ = kwargs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, state_size, action_size, model, optimiser, memory , config_data, seed = 122334):\n",
    "        # configuration data\n",
    "        self.config_data = config_data\n",
    "\n",
    "        self.seed = seed\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # model definition\n",
    "        self.model_local = model\n",
    "        self.model_target = model\n",
    "        self.optimizer = optimiser\n",
    "        self.optimizer = self.optimizer(self.model_local.parameters(), lr = self.config_data.LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = memory\n",
    "\n",
    "        # update_time_learning_step\n",
    "        self.t_step = 0\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        self.t_step = (self.t_step + 1) % self.config_data.UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            if len(self.memory) > self.config_data.BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, self.config_data.GAMMA)\n",
    "\n",
    "    def act(self, state, policy):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.model_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.model_local(state)\n",
    "        self.model_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        return policy.get_action(action_values.cpu().data.numpy())\n",
    "\n",
    "\n",
    "        #if random.random() > eps:\n",
    "        #    return np.argmax(action_values.cpu().data.numpy())\n",
    "        #else:\n",
    "        #    return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        next_states = torch.tensor(next_states).float()\n",
    "        rewards = torch.tensor(rewards).float()\n",
    "        actions = torch.tensor(actions).long()\n",
    "        states = torch.tensor(states).float()\n",
    "        dones = torch.tensor(dones).float()\n",
    "            # Get max predicted Q values (for next states) from target model (without ddqn)\n",
    "        Q_targets_next = self.model_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "    \n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.model_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # update target network \n",
    "        self.soft_update(self.model_local, self.model_target, self.config_data.TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "\n",
    "\n",
    "def dqn(env, agent, policy, n_episodes=10000, max_t=2000, stop_at_goal = True, goal = None):\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    #eps = eps_start                    # initialize epsilon\n",
    "    solved_in = None\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, policy)\n",
    "            print(action)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        #eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if stop_at_goal:\n",
    "            if np.mean(scores_window)>=goal:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "                torch.save(agent.model_local.state_dict(), \"checkpoint.pth\")\n",
    "                solved_in = i_episode-100\n",
    "                break\n",
    "        elif i_episode==2000:\n",
    "            torch.save(agent.model_local.state_dict(), \"checkpoint_final.pth\")\n",
    "        policy.update(i_episode)\n",
    "    return scores, solved_in\n",
    "\n",
    "\n",
    "dqn_config_data = config(BUFFER_SIZE = int(1e5), BATCH_SIZE = 64, GAMMA = 0.99, TAU = 1e-3, LR = 5e-4, UPDATE_EVERY = 4)\n",
    "env1 = environments.environment_gym('Acrobot-v1')\n",
    "env = environments.env_wrapper(env1)\n",
    "model = LinearModel(env.env.observation_space().shape[0],env.action_size())\n",
    "optimiser = optim.Adam\n",
    "rb = ReplayBuffer(action_size = n_action,buffer_size = dqn_config_data.BUFFER_SIZE, batch_size = dqn_config_data.BATCH_SIZE,seed = 122334)\n",
    "eps = epsilon(eps_start = 1.0, eps_decay = 0.8, eps_min = 0.01)\n",
    "policy = epsilon_greedy(eps,1)\n",
    "\n",
    "agent = Agent(env.env.observation_space().shape[0],env.action_size(),model = model, optimiser = optimiser, memory = rb, config_data = dqn_config_data)\n",
    "scores, solved_in = dqn(env, agent,policy = policy, stop_at_goal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = epsilon(eps_start = 1.0, eps_decay = 0.9999, eps_min = 0.01)\n",
    "policy = epsilon_greedy(eps,1)\n",
    "policy.epsilon.eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "75630736 -0.17848979]]\n[[ 0.46397853 -0.5510671  -0.04457767]]\n[[ 0.59319925 -0.447356    0.01699113]]\n[[ 0.41397443 -0.6244306  -0.12113746]]\n[[ 0.14323497 -0.8835794  -0.2800759 ]]\n[[-0.07386082 -1.0830007  -0.3639683 ]]\n[[-0.36589167 -1.2248814  -0.35781342]]\n[[-0.34022188 -1.058783   -0.21323614]]\n[[-0.06425932 -0.6827555   0.07373893]]\n[[ 0.20693387 -0.43676287  0.24408682]]\n[[ 0.43581992 -0.488754   -0.13457015]]\n[[ 0.24029328 -0.7339262  -0.39464113]]\n[[ 0.11335936 -0.8950131  -0.51214635]]\n[[-0.11004026 -1.1684535  -0.6512948 ]]\n[[-0.5460116  -1.431013   -0.64530593]]\n[[ 0.51152474 -0.26496205  0.26446033]]\n[[ 0.6267312  -0.23916444  0.29641265]]\n[[-0.2100182  -1.1256366  -0.46123135]]\n[[-0.32113773 -1.1689343  -0.38560826]]\n[[-0.06201179 -0.888708   -0.19556847]]\n[[ 0.15859357 -0.717194   -0.10679504]]\n[[ 0.27643    -0.68188286 -0.12213301]]\n[[ 0.30546486 -0.7164922  -0.17895004]]\n[[ 0.23397939 -0.8183421  -0.2613606 ]]\n[[ 0.05066356 -0.9775595  -0.3296924 ]]\n[[ 0.00948291 -0.97494286 -0.28210106]]\n[[ 0.00168215 -0.9283743  -0.21003029]]\n[[-0.10856915 -0.9924376  -0.23201464]]\n[[-0.00381764 -0.7987     -0.06560142]]\n[[ 0.02608075 -0.76763844 -0.05749635]]\n[[ 0.20829287 -0.597458    0.03020874]]\n[[ 0.21090038 -0.6524991  -0.08242548]]\n[[ 0.15742034 -0.7652062  -0.23330632]]\n[[ 0.12808765 -0.84274745 -0.3335511 ]]\n[[ 0.05937686 -0.9542109  -0.4303916 ]]\n[[ 0.04185218 -0.99439156 -0.44466794]]\n[[-0.05178498 -1.1046623  -0.4928518 ]]\n[[-0.12581676 -1.1691526  -0.49424356]]\n[[-0.2253327  -1.2310194  -0.50243944]]\n[[-0.18339618 -1.109265   -0.38849583]]\n[[ 0.04900598 -0.77157784 -0.10524327]]\n[[ 0.26026338 -0.54842734  0.07992563]]\n[[ 0.4535936  -0.38071603  0.20015825]]\n[[-0.15809847 -1.0593603  -0.5025157 ]]\n[[-0.30204737 -1.2312913  -0.5762122 ]]\n[[-0.1263303  -0.9663126  -0.34138495]]\n[[ 0.14443128 -0.7169268  -0.17388144]]\n[[ 0.44913977 -0.46335867  0.03363447]]\n[[ 0.5835483  -0.38054848  0.11525571]]\n[[-0.03451678 -0.9830395  -0.30605263]]\n[[-0.14123528 -1.0457793  -0.30406258]]\n[[-0.23364161 -1.0761052  -0.28488135]]\n[[-0.21342404 -0.97911394 -0.18410653]]\n[[-0.17112346 -0.8902619  -0.1152629 ]]\n[[ 0.19884677 -0.5614944   0.05940498]]\n[[ 0.32661402 -0.62264544 -0.19791602]]\n[[ 0.26130453 -0.74671865 -0.3599062 ]]\n[[ 0.11405848 -0.9343611  -0.5053675 ]]\n[[-0.00730848 -1.0739012  -0.55665255]]\n[[-0.3940328 -1.4348711 -0.6708603]]\n[[-0.03967497 -0.6631069  -0.04648782]]\n[[ 0.28432825 -0.3593824   0.21578456]]\n[[ 0.55380106 -0.19372295  0.35100734]]\n[[ 0.67835265 -0.1521375   0.3048767 ]]\n[[-0.33285943 -1.2782423  -0.7184315 ]]\n[[-0.53883356 -1.3360615  -0.5872902 ]]\n[[-0.2612628 -0.9674287 -0.3714527]]\n[[ 0.3558326  -0.44486713  0.02065922]]\n[[ 0.52913666 -0.36427265  0.12204118]]\n[[ 0.40142483 -0.5410012   0.00312071]]\n[[ 0.22769423 -0.6903527  -0.10964821]]\n[[ 0.01502813 -0.8838439  -0.24092959]]\n[[-0.17952956 -1.053134   -0.33547047]]\n[[-0.21652196 -1.032752   -0.2802845 ]]\n[[-0.14142434 -0.8908758  -0.16722864]]\n[[-0.02565281 -0.85082316 -0.21677744]]\n[[ 0.17892267 -0.71232116 -0.17480442]]\n[[ 0.3221368  -0.64625    -0.20410648]]\n[[ 0.02642398 -1.0562611  -0.5537481 ]]\n[[-0.12088966 -1.2104293  -0.603324  ]]\n[[-0.28763875 -1.2641308  -0.5345513 ]]\n[[-0.19950126 -1.0514183  -0.35017145]]\n[[-0.17169751 -0.9240228  -0.2398717 ]]\n[[ 0.34579667 -0.42731243  0.1618337 ]]\n[[ 0.2676306  -0.5852062  -0.14016113]]\n[[-0.06376994 -0.98795164 -0.5263851 ]]\n[[-0.2824021  -1.2640648  -0.68999195]]\n[[-0.31927568 -1.3119756  -0.65592635]]\n[[-0.39725506 -1.3768531  -0.65892947]]\n[[-0.02643044 -0.8864975  -0.28790897]]\n[[ 0.20707868 -0.6441605  -0.08533891]]\n[[ 0.27316707 -0.6076977  -0.03527498]]\n[[ 0.33560786 -0.55741835  0.01976015]]\n[[ 0.24408343 -0.6561613  -0.05657428]]\n[[-0.14902988 -1.0126216  -0.33469304]]\n[[-0.26321217 -1.0765457  -0.34762222]]\n[[-0.23731299 -1.0361923  -0.31763053]]\n[[-0.15284261 -0.96055186 -0.28021246]]\n[[ 0.02979326 -0.81264853 -0.20185137]]\n[[ 0.13103323 -0.78329    -0.22014427]]\n[[ 0.17506143 -0.80368066 -0.26610768]]\n[[ 0.2845112  -0.7174653  -0.21178034]]\n[[-0.3198201 -1.2726016 -0.5234685]]\n[[-0.33917108 -1.182191   -0.41964492]]\n[[-0.3091527  -1.0336746  -0.29263297]]\n[[-0.12763992 -0.7642919  -0.0766389 ]]\n[[ 0.33650264 -0.38775843  0.19335045]]\n[[ 0.4681168  -0.3399146   0.14471664]]\n[[-0.51651376 -1.5443164  -0.8303994 ]]\n[[-0.11647183 -0.7595843  -0.28696758]]\n[[ 0.52458185 -0.29062754  0.220351  ]]\n[[ 0.5155997  -0.3467619   0.18231814]]\n[[ 0.41603115 -0.43861955  0.07457074]]\n[[ 0.14472544 -0.6997957  -0.16542037]]\n[[-0.01850624 -0.84341586 -0.2824937 ]]\n[[-0.28153902 -1.1136136  -0.4693058 ]]\n[[-0.4568905 -1.2798537 -0.5435457]]\n[[-0.40208688 -1.1417154  -0.39759743]]\n[[-0.09467022 -0.831451   -0.195445  ]]\n[[ 0.06711554 -0.9688839  -0.39540547]]\n[[-0.1323115  -1.140537   -0.47606522]]\n[[-0.29501805 -1.2350552  -0.5058623 ]]\n[[ 0.35300612 -0.415963   -0.11760432]]\n[[ 0.14011174 -0.65548944 -0.39599028]]\n[[-0.24227294 -1.1513522  -0.77923185]]\n[[-0.39346585 -1.373265   -0.85737264]]\n[[-0.5456504 -1.5647614 -0.8955023]]\n[[-0.45025787 -1.326467   -0.663991  ]]\n[[-0.2247782  -1.0149472  -0.46527576]]\n[[ 0.11031814 -0.65452015 -0.18694022]]\n[[ 0.07908786 -0.74534696 -0.0996227 ]]\n[[ 0.04447912 -0.741472   -0.10375226]]\n[[ 0.02227886 -0.7326206  -0.11939957]]\n[[-0.15057214 -0.9174273  -0.32878655]]\n[[-0.21559046 -1.1441222  -0.5673363 ]]\n[[-0.08470541 -1.0592326  -0.5100335 ]]\n[[ 0.04602166 -0.9677804  -0.44997212]]\n[[ 0.14184691 -0.8929816  -0.38847223]]\n[[ 0.17689548 -0.85199773 -0.33455658]]\n[[-0.2440781  -1.1812124  -0.46727866]]\n[[-0.35834736 -1.1975579  -0.44860345]]\n[[-0.23148584 -0.9302365  -0.21592988]]\n[[-0.07660799 -0.69452107 -0.01029356]]\n[[ 0.06434108 -0.55280024  0.10939702]]\n[[-0.0537824  -0.98829323 -0.57886636]]\n[[-0.26507095 -1.2673895  -0.7557855 ]]\n[[-0.4607408 -1.4997169 -0.8561251]]\n[[-0.47076643 -1.4598893  -0.77026516]]\n[[-0.24550717 -1.0538573  -0.479149  ]]\n[[ 0.00466519 -0.7146441  -0.21351808]]\n[[ 0.11987329 -0.5973196  -0.08375218]]\n[[ 0.34219527 -0.39019397  0.13802895]]\n[[ 0.3975276  -0.38513482  0.17579404]]\n[[ 0.47659037 -0.31646553  0.21140793]]\n[[-0.20699123 -0.99788165 -0.4635893 ]]\n[[-0.35976434 -1.1638242  -0.55859315]]\n[[-0.48244214 -1.3009632  -0.6169444 ]]\n[[-0.42451462 -1.2331222  -0.5338955 ]]\n[[-0.13692747 -0.9969176  -0.4044808 ]]\n[[ 0.14069577 -0.7740426  -0.26443115]]\n[[ 0.35732895 -0.618781   -0.16439737]]\n[[ 0.29828203 -0.71634924 -0.24808592]]\n[[-0.0428969  -1.0336139  -0.42548087]]\n[[-0.27807385 -1.2376045  -0.5295983 ]]\n[[-0.34450293 -1.0780272  -0.33965224]]\n[[-0.15387143 -0.7629929  -0.06615078]]\n[[ 0.11184725 -0.46620739  0.18724132]]\n[[ 0.3101498  -0.32635427  0.2658775 ]]\n[[ 0.33735988 -0.37849176  0.115192  ]]\n[[-0.23191354 -1.1676388  -0.81324595]]\n[[-0.39125994 -1.3967718  -0.8965243 ]]\n[[-0.55695724 -1.5946387  -0.94049436]]\n[[-0.29740924 -1.070172   -0.51699257]]\n[[-0.00232298 -0.68966126 -0.22982933]]\n[[ 0.12948212 -0.5643004  -0.08935343]]\n[[ 0.23962057 -0.48280525  0.03371446]]\n[[ 0.4148147  -0.37859684  0.17371586]]\n[[ 0.38424015 -0.39405382  0.11076333]]\n[[-0.15759534 -0.93409157 -0.40531683]]\n[[-0.3287069 -1.1115245 -0.5235828]]\n[[-0.50501853 -1.2979282  -0.5894052 ]]\n[[-0.04410408 -0.92050874 -0.37859827]]\n[[ 0.17299241 -0.76803017 -0.2814754 ]]\n[[ 0.301802   -0.6853975  -0.21341285]]\nEpisode 3\tAverage Score: -500.00[[-0.02982713 -0.9168272  -0.3135461 ]]\n[[-0.04104144 -0.9180485  -0.30820236]]\n[[-0.11735675 -0.9903202  -0.35926494]]\n[[-0.09194415 -0.9398835  -0.31415644]]\n[[-0.13155001 -0.97889817 -0.3455642 ]]\n[[-0.0857513  -0.9251014  -0.30383727]]\n[[-0.02963463 -0.873315   -0.27108568]]\n[[ 0.08388389 -0.7671791  -0.20350605]]\n[[-0.00507602 -0.91284627 -0.36640495]]\n[[-0.13153951 -1.0591758  -0.4776041 ]]\n[[-0.1820475  -1.1032009  -0.49159935]]\n[[-0.25326163 -1.0751865  -0.42869958]]\n[[-0.07561217 -0.8407025  -0.24580267]]\n[[ 0.08882914 -0.68292886 -0.11190357]]\n[[ 0.2918862  -0.5096557   0.03241772]]\n[[ 0.26296726 -0.5922624  -0.12152044]]\n[[ 0.09855192 -0.7561339  -0.289308  ]]\n[[-0.09651276 -0.95964867 -0.4543724 ]]\n[[-0.5248179  -1.404272   -0.70933425]]\n[[-0.43183854 -1.2391207  -0.53537285]]\n[[-0.29454535 -1.0526855  -0.38772225]]\n[[ 0.04804477 -0.90768623 -0.3684339 ]]\n[[-0.11193337 -1.0473163  -0.43965754]]\n[[-0.26240543 -0.994411   -0.310026  ]]\n[[-0.18079954 -0.8733687  -0.21166153]]\n[[ 0.04163913 -0.69643927 -0.10067758]]\n[[ 0.06055402 -0.85448337 -0.3445891 ]]\n[[-0.14107603 -1.0988482  -0.53492194]]\n[[-0.21723732 -1.1625661  -0.5513874 ]]\n[[-0.18623644 -1.0868833  -0.45968634]]\n[[-0.11115739 -0.9656157  -0.34104455]]\n[[-0.04365531 -0.8649182  -0.24684401]]\n[[-0.01815024 -0.83033025 -0.22152051]]\n[[ 6.1478652e-04 -8.1268191e-01 -2.1821937e-01]]\n[[ 0.0686305  -0.7452675  -0.18567814]]\n[[-0.02545052 -0.86682075 -0.315236  ]]\n[[-0.135606   -1.0146428  -0.46941236]]\n[[-0.23504436 -1.1454772  -0.5598526 ]]\n[[-0.18211499 -1.0820718  -0.49110943]]\n[[-0.16235255 -1.0599889  -0.4645986 ]]\n[[-0.18936494 -1.0861145  -0.4793008 ]]\n[[-0.1951437  -1.076977   -0.46479267]]\n[[-0.0920402  -0.930768   -0.33228204]]\n[[-0.04382935 -0.8633661  -0.2491869 ]]\n[[-0.11876456 -0.93571174 -0.3208157 ]]\n[[-0.14341888 -1.0131071  -0.42166317]]\n[[-0.05241906 -0.9116167  -0.33537355]]\n[[ 0.00876417 -0.8560208  -0.27512273]]\n[[ 0.00386593 -0.8485192  -0.2578845 ]]\n[[-0.20457716 -1.0332626  -0.3919109 ]]\n[[-0.2175077  -0.99319017 -0.3450424 ]]\n[[-0.17688091 -1.0954263  -0.5182321 ]]\n[[-0.16696636 -0.93509024 -0.31996995]]\n[[-0.0461057  -0.86954665 -0.30056077]]\n[[-0.32120797 -1.2016226  -0.5921386 ]]\n[[-0.19411075 -1.0485148  -0.455315  ]]\n[[-0.09178122 -0.9357015  -0.36105782]]\n[[ 0.06562799 -0.7743832  -0.22168991]]\n[[ 0.1838212  -0.6648966  -0.12940356]]\n[[ 0.09677154 -0.77191174 -0.22871247]]\n[[ 0.01703311 -0.8487056  -0.2949362 ]]\n[[-0.30941978 -1.1608282  -0.5199915 ]]\n[[-0.25827634 -1.0030017  -0.35737973]]\n[[-0.10740479 -0.8764028  -0.28549236]]\n[[ 0.02892818 -0.779322   -0.22826587]]\n[[ 0.05550052 -0.8095529  -0.28139055]]\n[[-0.18689936 -1.1145941  -0.53146213]]\n[[-0.28366572 -1.1846267  -0.56374526]]\n[[-0.214362   -1.0034729  -0.37825772]]\n[[-0.126958   -0.8705469  -0.25453427]]\n[[ 0.04180347 -0.68190324 -0.0862232 ]]\n[[ 0.13991259 -0.64087594 -0.11408846]]\n[[-0.42192137 -1.3015225  -0.6924899 ]]\n[[-0.31290564 -1.1527566  -0.5437916 ]]\n[[-0.11205606 -0.9460713  -0.38645953]]\n[[ 0.02232808 -0.85381275 -0.2930456 ]]\n[[-0.24412562 -1.0687666  -0.42835814]]\n[[-0.20198232 -0.9470475  -0.30385557]]\n[[-0.16582817 -0.9035046  -0.28249386]]\n[[-0.06587507 -0.82291675 -0.23759699]]\n[[-0.05041263 -0.8560775  -0.3010465 ]]\n[[-0.01275213 -0.906606   -0.41648674]]\n[[-0.00849729 -0.9205892  -0.4386902 ]]\n[[-0.4380178 -1.3458941 -0.7116178]]\n[[-0.33118457 -1.1463637  -0.5261914 ]]\n[[-0.10142624 -0.8269216  -0.23816305]]\n[[ 0.08837857 -0.63324124 -0.06076042]]\n[[-0.02255041 -0.84279525 -0.3014595 ]]\n[[-0.1544246  -0.9932651  -0.44043005]]\n[[-0.2834527 -1.1342133 -0.5498597]]\n[[-0.39938295 -1.2225761  -0.59035   ]]\n[[-0.3520743 -1.1439047 -0.5264972]]\n[[-0.1368393 -0.9026812 -0.3304704]]\n[[ 0.01784043 -0.7732724  -0.22902365]]\n[[ 0.13215609 -0.6996702  -0.17418118]]\n[[-0.29714498 -1.1696343  -0.5501703 ]]\n[[-0.3945854  -1.1441078  -0.48891252]]\n[[-0.01309736 -0.72379005 -0.13809527]]\n[[ 0.0473749  -0.7183764  -0.15969297]]\n[[ 0.04546396 -0.7744127  -0.24449094]]\n[[-0.0182638  -0.8815314  -0.36694974]]\n[[-0.12838429 -1.0222374  -0.4959222 ]]\n[[-0.1914266 -1.092212  -0.5421944]]\n[[-0.24443671 -1.1369245  -0.55978984]]\n[[ 0.03260199 -0.7113331  -0.14897677]]\n[[-0.14945966 -0.99483025 -0.427444  ]]\n[[-0.24714233 -0.9856038  -0.39065364]]\n[[-0.05165525 -0.8244308  -0.26951703]]\n[[ 0.00956452 -0.8004265  -0.254219  ]]\n[[-0.11695035 -0.9795246  -0.40809214]]\n[[-0.15121247 -0.9951726  -0.40770972]]\n[[-0.1956346  -0.99900293 -0.3930473 ]]\n[[-0.25817347 -1.0446613  -0.42463338]]\n[[-0.22427417 -0.98075306 -0.36894372]]\n[[-0.15443048 -1.0076822  -0.45527884]]\n[[-0.18889321 -1.0629655  -0.5066316 ]]\n[[-0.15296917 -1.0299724  -0.46965787]]\n[[-0.21272208 -1.0623858  -0.4744433 ]]\n[[-0.19586925 -1.01174    -0.4158684 ]]\n[[-0.22474253 -0.9860521  -0.375762  ]]\n[[-0.14365225 -0.87875986 -0.27565414]]\n[[ 0.00548537 -0.72431576 -0.14217946]]\n[[ 0.04603137 -0.7459129  -0.24029724]]\n[[-0.39721397 -1.2740878  -0.7118518 ]]\n[[-0.39531726 -1.2350382  -0.6354381 ]]\n[[-0.28472963 -1.0698979  -0.50308025]]\n[[-0.0773167 -0.8415573 -0.3042935]]\n[[ 0.02095617 -0.7940607  -0.24834153]]\n[[-0.03556541 -0.8653328  -0.30103907]]\n[[-0.03109489 -0.84069175 -0.27511612]]\n[[-0.17113975 -0.9800111  -0.3965386 ]]\n[[-0.17921212 -0.9600359  -0.37094924]]\n[[-0.30503806 -1.0702448  -0.4663326 ]]\n[[-0.27336657 -1.0694481  -0.49162775]]\n[[-0.1818606 -1.0241675 -0.4640502]]\n[[-0.1408404 -0.9403148 -0.3714033]]\n[[-0.10616643 -0.81433845 -0.21837738]]\n[[-0.05481266 -0.78664684 -0.22567481]]\n[[-0.17028494 -0.99269533 -0.48100784]]\n[[-0.2597516  -1.1245629  -0.60527545]]\n[[-0.35756332 -1.255368   -0.6895065 ]]\n[[-0.30975556 -1.1703917  -0.604205  ]]\n[[-0.08863023 -0.79256856 -0.22747791]]\n[[-0.04172562 -0.7814517  -0.2006927 ]]\n[[ 0.02743359 -0.7144542  -0.16395713]]\n[[-0.19883999 -0.99559844 -0.47274786]]\n[[-0.32112822 -1.1548518  -0.61854017]]\n[[-0.33467323 -1.1338311  -0.58514965]]\n[[-0.00490753 -0.8123392  -0.28211728]]\n[[ 0.01222366 -0.79838    -0.23866117]]\n[[-0.43483987 -1.1794198  -0.53733706]]\n[[-0.3391713  -1.026965   -0.39081955]]\n[[-0.30810177 -0.9926649  -0.37157953]]\n[[-0.25250936 -0.96112055 -0.3677739 ]]\n[[-0.05350665 -0.87699187 -0.379535  ]]\n[[-0.03239402 -0.9131317  -0.44725007]]\n[[-0.01333135 -0.92160964 -0.4704925 ]]\n[[-0.44172624 -1.3696244  -0.78152907]]\n[[-0.49692914 -1.3477157  -0.7294483 ]]\n[[-0.5029645  -1.2416531  -0.63334614]]\n[[ 0.11081831 -0.60220015 -0.06559703]]\n[[ 0.01371227 -0.7980971  -0.3611781 ]]\n[[-0.05314043 -0.880702   -0.4641836 ]]\n[[-0.15378976 -0.99834913 -0.57230806]]\n[[-0.53259385 -1.433395   -0.87307847]]\n[[-0.65116704 -1.5186588  -0.8967613 ]]\n[[ 0.14859855 -0.5766641  -0.08394074]]\n[[ 0.17895085 -0.5962312  -0.07577999]]\n[[ 0.22389531 -0.5565258  -0.04100303]]\n[[-0.1922633  -0.99437195 -0.45848265]]\n[[-0.43274194 -1.2379687  -0.64544576]]\n[[-0.52806526 -1.2313317  -0.5745446 ]]\n[[-0.27404684 -0.93688333 -0.33560458]]\n[[-0.10760884 -0.9012777  -0.382863  ]]\n[[-0.08185267 -0.94837165 -0.45817694]]\n[[-0.14871341 -1.0827204  -0.58238083]]\n[[-0.43417794 -1.1600986  -0.5741335 ]]\n[[-0.3778209 -0.995379  -0.427224 ]]\n[[-0.26784682 -0.8100437  -0.25045568]]\n[[-0.1277652  -0.65340793 -0.0889267 ]]\n[[ 0.11638415 -0.61516654 -0.11759759]]\n[[-0.12593393 -0.9618249  -0.537747  ]]\n[[-0.32002926 -1.2025769  -0.73968047]]\n[[-0.5869813 -1.4809085 -0.8925326]]\n[[-0.41875863 -1.1725676  -0.61409664]]\n[[-0.10852315 -0.81909966 -0.29872727]]\n[[ 0.02017845 -0.7103406  -0.18504   ]]\n[[ 0.08125021 -0.7070909  -0.18983623]]\n[[ 0.04272722 -0.7407321  -0.24463576]]\n[[-0.05134413 -0.82722783 -0.34663773]]\n[[-0.2297783 -1.0141941 -0.5204699]]\n[[-0.39706925 -1.1900718  -0.65498   ]]\n[[-0.58264023 -1.348939   -0.7266182 ]]\n[[-0.14176667 -0.9222674  -0.4177598 ]]\n[[ 0.00273196 -0.81948495 -0.33233264]]\n[[-0.32420796 -1.1904882  -0.6047203 ]]\n[[-0.4480628  -1.0879246  -0.44420236]]\n[[-0.31302014 -0.87726235 -0.24764352]]\n[[ 0.01673831 -0.58685744 -0.01663993]]\n[[ 0.12026364 -0.57262355 -0.08107954]]\n[[ 0.12445    -0.6437615  -0.25162056]]\n[[ 0.09753864 -0.71095586 -0.39863506]]\n[[-0.1011414  -0.96455586 -0.65464425]]\n[[-0.6115526 -1.5852759 -1.0709741]]\n[[-0.7036407 -1.5070703 -0.9185609]]\n[[-0.53482234 -1.1838254  -0.67044675]]\n[[-0.33360398 -0.886106   -0.43282527]]\n[[-0.16791904 -0.7007028  -0.26421177]]\n[[ 0.08761848 -0.471246   -0.01342977]]\n[[-0.6154896 -1.4506295 -0.8970914]]\n[[-0.73516977 -1.5294544  -0.89305896]]\n[[-0.6147643 -1.305534  -0.665066 ]]\n[[-0.39239126 -1.0193921  -0.42221314]]\n[[-0.25244087 -0.9050664  -0.3486047 ]]\n[[-0.27152485 -1.192123   -0.6700988 ]]\n[[-0.5423879 -1.2621313 -0.6661513]]\n[[-0.4691397  -1.0627701  -0.49287042]]\n[[ 0.24314095 -0.43381742  0.06860445]]\n[[ 0.00954542 -0.7809696  -0.43156752]]\n[[-0.6886297 -1.6154449 -1.0745884]]\n[[-0.82340324 -1.6962541  -1.0840261 ]]\n[[-0.738997   -1.4654833  -0.90071297]]\n[[-0.548848   -1.1470742  -0.68100584]]\n[[-0.34113848 -0.8810541  -0.49347323]]\n[[ 0.16681084 -0.49241102 -0.04467096]]\n[[-0.5046093  -1.281336   -0.70301104]]\n[[-0.72799903 -1.3619308  -0.68301415]]\n[[-0.5524936 -1.0856118 -0.4367452]]\n[[-0.2800669  -0.79532224 -0.19816537]]\n[[ 0.02085986 -0.7241869  -0.2258748 ]]\n[[ 0.17892188 -0.6652145  -0.23530664]]\n[[ 0.09055362 -0.82273746 -0.43204927]]\n[[-0.30928427 -1.2600158  -0.7718014 ]]\n[[-0.7217212 -1.5681398 -0.9687879]]\n[[-0.2973746  -0.60973847 -0.15467866]]\n[[-0.09255613 -0.41016722  0.06814604]]\n[[ 0.16681692 -0.25450236  0.2705976 ]]\n[[ 0.34892607 -0.36862832  0.05477887]]\n[[ 0.00102807 -0.7841209  -0.51384676]]\n[[-0.27995178 -1.1214727  -0.8017302 ]]\n[[-0.09785797 -0.58592844 -0.25788578]]\n[[ 0.30685014 -0.43118137  0.0840891 ]]\n[[-0.00797407 -0.77973855 -0.26148   ]]\n[[-0.23369248 -1.0065029  -0.4725723 ]]\n[[ 0.09785265 -0.65643746 -0.19054747]]\n[[ 0.05992931 -0.80748904 -0.42525825]]\n[[-0.08563528 -1.0203471  -0.65380394]]\n[[-0.25924534 -1.2265788  -0.8040177 ]]\n[[-0.04061816 -0.35703185  0.02795639]]\n[[ 0.20238346 -0.21207216  0.2540234 ]]\n[[ 0.38730332 -0.19289689  0.33812755]]\n[[ 0.40159744 -0.2913893   0.17659739]]\n[[ 0.29147804 -0.40904725 -0.06375782]]\n[[ 0.14713918 -0.527634   -0.26180744]]\nEpisode 4\tAverage Score: -500.00[[-0.29718417 -1.0789838  -0.52751786]]\n[[-0.41496673 -1.2129654  -0.6555344 ]]\n[[-0.39737839 -1.1767895  -0.62506056]]\n[[-0.25090083 -0.9981218  -0.4563692 ]]\n[[-0.10984819 -0.8551016  -0.31567356]]\n[[-0.07980386 -0.8756522  -0.3480322 ]]\n[[-0.52618885 -1.2084541  -0.6175155 ]]\n[[-0.31371558 -1.1772718  -0.6472554 ]]\n[[-0.46878397 -1.2436328  -0.6656462 ]]\n[[-0.23604128 -0.92075014 -0.34965506]]\n[[-0.20949557 -0.9609785  -0.4105023 ]]\n[[-0.47115672 -1.2836618  -0.723378  ]]\n[[-0.47147405 -1.2391232  -0.6825213 ]]\n[[-0.37439364 -1.0873376  -0.54232585]]\n[[-0.25977132 -0.9462054  -0.40528303]]\n[[-0.08243225 -0.81171733 -0.2609288 ]]\n[[-0.01382407 -0.7605045  -0.22404823]]\n[[-0.01159305 -0.7711232  -0.26762035]]\n[[-0.5376865 -1.3697865 -0.8399926]]\n[[-0.5755989 -1.3710084 -0.7982049]]\n[[-0.33020622 -1.0564001  -0.52343076]]\n[[-0.14460608 -0.88648915 -0.3667529 ]]\n[[-0.05415741 -0.84141636 -0.32562685]]\n[[-0.09629133 -0.9373418  -0.43204522]]\n[[-0.57205456 -1.1686304  -0.58515304]]\n[[-0.39753592 -0.9133856  -0.35040727]]\n[[-0.2535885  -0.7783879  -0.22196035]]\n[[-0.11915187 -0.71388435 -0.1604697 ]]\n[[ 0.08103215 -0.5992015  -0.06756132]]\n[[-0.22269648 -1.1020643  -0.67133975]]\n[[-0.19922294 -0.67015713 -0.22612011]]\n[[ 0.13998362 -0.50727004  0.02106646]]\n[[ 0.05545845 -0.7286781  -0.25099176]]\n[[-0.39194503 -1.2348605  -0.7463121 ]]\n[[-0.6990129 -1.4922056 -0.9022969]]\n[[-0.4460773  -0.98683333 -0.46428105]]\n[[-0.0749374  -0.7178829  -0.21134649]]\n[[ 0.02732706 -0.7161046  -0.20514789]]\n[[-0.02836779 -0.8715606  -0.38864738]]\n[[-0.40424508 -1.2731943  -0.7441155 ]]\n[[-0.72340167 -1.4660984  -0.8723736 ]]\n[[-0.26107264 -0.6870016  -0.15473057]]\n[[ 0.21630335 -0.5298971  -0.09790071]]\n[[-0.01643916 -0.8096573  -0.52430856]]\n[[-0.98166275 -1.9046283  -1.342453  ]]\n[[-0.9785727 -1.7021579 -1.1569642]]\n[[-0.06470378 -0.5067053  -0.14742377]]\n[[ 0.29754496 -0.38318574  0.13324167]]\n[[ 0.32495815 -0.4131708   0.09475993]]\n[[ 0.20006047 -0.53178227 -0.0870944 ]]\n[[-0.30826402 -1.0647447  -0.6538563 ]]\n[[-0.96020794 -1.5914378  -0.9583916 ]]\n[[ 0.18180618 -0.4731925   0.0302641 ]]\n[[ 0.25108403 -0.56048155 -0.11840326]]\n[[-0.6929903  -1.042298   -0.59616923]]\n[[ 0.09901235 -0.15902847  0.33137727]]\n[[ 0.42030996 -0.29673624 -0.03583112]]\n[[-0.01464061 -0.7297462  -0.5453718 ]]\n[[-1.1928978 -2.1253235 -1.5628474]]\n[[-1.075247  -1.7282816 -1.1736014]]\n[[-0.81348896 -1.2113764  -0.7756889 ]]\n[[-0.2168262  -0.4811003  -0.18297939]]\n[[ 0.0021378  -0.36492062 -0.04463229]]\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2bd17bf530c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn_config_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolved_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_at_goal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-2bd17bf530c4>\u001b[0m in \u001b[0;36mdqn\u001b[0;34m(env, agent, n_episodes, max_t, eps_start, eps_end, eps_decay, stop_at_goal, goal)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2bd17bf530c4>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2bd17bf530c4>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, experiences, gamma)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class config:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__ = kwargs\n",
    "\n",
    "\n",
    "eps = epsilon(eps_start = 1.0, eps_decay = 0.9999, eps_min = 0.01)\n",
    "policy = epsilon_greedy(eps,200)\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, state_size, action_size, model, optimiser, memory , config_data, seed = 122334):\n",
    "        # configuration data\n",
    "        self.config_data = config_data\n",
    "\n",
    "        self.seed = seed\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # model definition\n",
    "        self.model_local = model\n",
    "        self.model_target = model\n",
    "        self.optimizer = optimiser\n",
    "        self.optimizer = self.optimizer(self.model_local.parameters(), lr = self.config_data.LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = memory\n",
    "\n",
    "        # update_time_learning_step\n",
    "        self.t_step = 0\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        self.t_step = (self.t_step + 1) % self.config_data.UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            if len(self.memory) > self.config_data.BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, self.config_data.GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.model_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.model_local(state)\n",
    "        self.model_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if np.random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            print(action_values.cpu().data.numpy())\n",
    "            return np.random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        next_states = torch.tensor(next_states).float()\n",
    "        rewards = torch.tensor(rewards).float()\n",
    "        actions = torch.tensor(actions).long()\n",
    "        states = torch.tensor(states).float()\n",
    "        dones = torch.tensor(dones).float()\n",
    "            # Get max predicted Q values (for next states) from target model (without ddqn)\n",
    "        Q_targets_next = self.model_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "    \n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.model_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # update target network \n",
    "        self.soft_update(self.model_local, self.model_target, self.config_data.TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "def dqn(env, agent, n_episodes=10000, max_t=2000, eps_start=1.0, eps_end=0.01, \\\n",
    "        eps_decay=0.8, stop_at_goal = True, goal = None):\n",
    "    \"\"\"Deep Q-Learning. Returns the scores and the number of episodes required to solve the environment if stop_at_goal\n",
    "    is true. If stop_at_goal is false, will return scores for n_episodes without stopping.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        env (env): Environment\n",
    "        agent (Agent): The agent\n",
    "        folder (string): the folder string name to deposit results\n",
    "        is_train_mode (boolean):If train mode is on or not.\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "        n_episodes (int) : Number of episodes\n",
    "        max_t (int) : Maximum number of time steps considered\n",
    "        stop_at_goal (boolean) : If true, will stop when environment is solved, else will continue for n_episodes\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    solved_in = None\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if stop_at_goal:\n",
    "            if np.mean(scores_window)>=goal:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "                torch.save(agent.qnetwork_local.state_dict(), \"checkpoint.pth\")\n",
    "                solved_in = i_episode-100\n",
    "                break\n",
    "        elif i_episode==2000:\n",
    "            torch.save(agent.model_local.state_dict(), \"checkpoint_final.pth\")\n",
    "    return scores, solved_in\n",
    "\n",
    "\n",
    "dqn_config_data = config(BUFFER_SIZE = int(1e5), BATCH_SIZE = 64, GAMMA = 0.99, TAU = 1e-3, LR = 5e-4, UPDATE_EVERY = 4)\n",
    "env1 = environments.environment_gym('Acrobot-v1')\n",
    "env = environments.env_wrapper(env1)\n",
    "model = LinearModel(env.env.observation_space().shape[0],env.action_size())\n",
    "optimiser = optim.Adam\n",
    "rb = ReplayBuffer(action_size = n_action,buffer_size = dqn_config_data.BUFFER_SIZE, batch_size = dqn_config_data.BATCH_SIZE,seed = 122334)\n",
    "\n",
    "agent = Agent(env.env.observation_space().shape[0],env.action_size(),model = model, optimiser = optimiser, memory = rb, config_data = dqn_config_data)\n",
    "scores, solved_in = dqn(env, agent, stop_at_goal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python36964bitmlenvconda9f54039d931e4029adcffd4ea832f0f0",
   "display_name": "Python 3.6.9 64-bit ('ml_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}